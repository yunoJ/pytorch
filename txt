CONTRIBUTING.md:       torch.cuda.synchronize()
CONTRIBUTING.md:       torch.cuda.synchronize()
CONTRIBUTING.md:       torch.cuda.synchronize()
benchmarks/fastrnns/bench.py:        torch.cuda.synchronize()
benchmarks/fastrnns/profile.py:        torch.cuda.synchronize()
torch/autograd/profiler.py:        torch.cuda.synchronize()
torch/autograd/profiler.py:        torch.cuda.synchronize()
torch/jit/__init__.py:        end.synchronize()
torch/cuda/__init__.pyi:def synchronize(device: _device_t) -> None: ...
torch/cuda/__init__.py:def synchronize(device=None):
torch/cuda/__init__.py:        device (torch.device or int, optional): device for which to synchronize.
torch/cuda/__init__.py:        return torch._C._cuda_synchronize()
torch/cuda/streams.py:            stream (Stream): a stream to synchronize.
torch/cuda/streams.py:    def synchronize(self):
torch/cuda/streams.py:        super(Stream, self).synchronize()
torch/cuda/streams.py:    device's progress, to accurately measure timing, and to synchronize CUDA
torch/cuda/streams.py:    def synchronize(self):
torch/cuda/streams.py:        super(Event, self).synchronize()
Binary file torch/bin/test_api matches
Binary file torch/bin/protoc matches
torch/nn/parallel/distributed.py:        variables, which will later be synchronized in the first
torch/nn/parallel/distributed.py:            ... ddp(another_input).backward()  # synchronize grads
Binary file torch/test/net_gpu_test matches
Binary file torch/test/utility_ops_gpu_test matches
Binary file torch/test/context_gpu_test matches
Binary file torch/test/mpi_gpu_test matches
Binary file torch/test/operator_gpu_test matches
Binary file torch/test/batch_matmul_op_gpu_test matches
Binary file torch/test/operator_fallback_gpu_test matches
Binary file torch/test/generate_proposals_op_util_nms_gpu_test matches
Binary file torch/test/cuda_tensor_interop_test matches
Binary file torch/test/blob_gpu_test matches
Binary file torch/test/event_gpu_test matches
Binary file torch/test/math_gpu_test matches
Binary file torch/test/roi_align_op_gpu_test matches
Binary file torch/test/generate_proposals_op_gpu_test matches
Binary file torch/test/cuda_packedtensoraccessor_test matches
Binary file torch/test/elementwise_op_gpu_test matches
Binary file torch/test/reshape_op_gpu_test matches
Binary file torch/test/cuda_stream_test matches
Binary file torch/lib/libc10_cuda.so matches
Binary file torch/lib/libgloo_cuda.a matches
torch/lib/c10d/ProcessGroupGloo.hpp:  // This work object is used to synchronize completion of the send or
torch/lib/c10d/ProcessGroupNCCL.hpp:// either WorkNCCL::wait() or WorkNCCL::synchronize(), both achieves the same
torch/lib/c10d/ProcessGroupNCCL.hpp:    // Same as calling synchronize() for NCCL work.
torch/lib/c10d/ProcessGroupNCCL.hpp:    void synchronize() override;
torch/lib/c10d/ProcessGroup.cpp:void ProcessGroup::Work::synchronize() {}
torch/lib/c10d/ProcessGroup.cpp:  synchronize();
torch/lib/c10d/ProcessGroupGloo.cpp:// synchronized with the current default streams. This is needed so
torch/lib/c10d/ProcessGroupGloo.cpp:    // Ensure the new stream is synchronized with the current stream.
torch/lib/c10d/ProcessGroupGloo.cpp:// and ensures that these streams are synchronized with the current default
torch/lib/c10d/ProcessGroupGloo.cpp:    // Ensure the new stream is synchronized with the current stream.
torch/lib/c10d/ProcessGroupGloo.cpp:  void synchronize() override {
torch/lib/c10d/ProcessGroupGloo.cpp:  void synchronize() override {
torch/lib/c10d/ProcessGroupGloo.cpp:  void synchronize() override {
torch/lib/c10d/ProcessGroupGloo.cpp:  void synchronize() override {
torch/lib/c10d/ProcessGroupGloo.cpp:  void synchronize() override {
torch/lib/c10d/ProcessGroupGloo.cpp:  void synchronize() override {
torch/lib/c10d/ProcessGroupGloo.cpp:  void synchronize() override {
torch/lib/c10d/ProcessGroupGloo.cpp:  // the unbound buffer to synchronize on completion of the send.
torch/lib/c10d/ProcessGroupGloo.cpp:  // the unbound buffer to synchronize on completion of the recv.
torch/lib/c10d/ProcessGroupGloo.cpp:  // the unbound buffer to synchronize on completion of the recv.
torch/lib/c10d/ProcessGroupNCCL.cpp:void ProcessGroupNCCL::WorkNCCL::synchronize() {
torch/lib/c10d/ProcessGroupNCCL.cpp:// Same as calling synchronize().
torch/lib/c10d/ProcessGroupNCCL.cpp:  synchronize();
torch/lib/c10d/ProcessGroup.hpp:// process groups can be used in parallel and synchronize accordingly.
torch/lib/c10d/ProcessGroup.hpp:    virtual void synchronize();
torch/lib/python3.7/site-packages/caffe2/contrib/gloo/gloo_test.py:    def synchronize(self, store_handler, value, comm_rank=None):
torch/lib/python3.7/site-packages/caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
torch/lib/python3.7/site-packages/caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
torch/lib/python3.7/site-packages/caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
torch/lib/python3.7/site-packages/caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
torch/lib/python3.7/site-packages/caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
torch/lib/python3.7/site-packages/caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
torch/lib/python3.7/site-packages/caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
torch/lib/python3.7/site-packages/caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
Binary file torch/lib/python3.7/site-packages/caffe2/python/caffe2_pybind11_state_gpu.cpython-37m-x86_64-linux-gnu.so matches
torch/lib/python3.7/site-packages/caffe2/python/data_parallel_model.py:                        to synchronize shards before a training epoch starts.
torch/lib/python3.7/site-packages/caffe2/python/data_parallel_model.py:    # synchronized values by the training net
Binary file torch/lib/libtorch_python.so matches
Binary file torch/lib/libcaffe2_detectron_ops_gpu.so matches
Binary file torch/lib/libprotocd.a matches
Binary file torch/lib/libc10d.a matches
Binary file torch/lib/libtorch.so matches
torch/csrc/autograd/profiler_cuda.cpp:  void synchronize() override {
torch/csrc/autograd/profiler.h:  virtual void synchronize() {
torch/csrc/autograd/profiler.cpp:          cuda_stubs->synchronize();
torch/csrc/autograd/profiler.cpp:    // for each gpu. we then use this event to synchronize time on the GPU
torch/csrc/distributed/c10d/init.cpp:      .def("synchronize", &::c10d::ProcessGroup::Work::synchronize)
torch/csrc/distributed/c10d/reducer.h:    // so that we can synchronize with them prior to kicking off the reduction.
torch/csrc/cuda/Module.cpp:  {"_cuda_synchronize", (PyCFunction)THCPModule_cudaSynchronize, METH_NOARGS, nullptr},
torch/csrc/cuda/Stream.cpp:static PyObject * THCPStream_synchronize(THCPStream *self) {
torch/csrc/cuda/Stream.cpp:  with_no_gil([&] { self->cuda_stream.synchronize(); });
torch/csrc/cuda/Stream.cpp:  {(char*)"synchronize",
torch/csrc/cuda/Stream.cpp:    (PyCFunction)THCPStream_synchronize, METH_NOARGS, nullptr},
torch/csrc/cuda/Event.cpp:static PyObject * THCPEvent_synchronize(THCPEvent *self) {
torch/csrc/cuda/Event.cpp:  with_no_gil([&] { self->cuda_event.synchronize(); });
torch/csrc/cuda/Event.cpp:  {(char*)"synchronize", (PyCFunction)THCPEvent_synchronize,
torch/csrc/api/include/torch/data/datasets/chunk.h:      // and evaluating stop_ always happen in a synchronized way
torch/csrc/api/include/torch/data/datasets/chunk.h:  // mutex to synchronize chunk sampler next() call.
torch/csrc/generic/StorageSharing.cpp:  // Already synchronized inside producer stream
torch/include/c10d/ProcessGroupGloo.hpp:  // This work object is used to synchronize completion of the send or
torch/include/c10d/ProcessGroupNCCL.hpp:// either WorkNCCL::wait() or WorkNCCL::synchronize(), both achieves the same
torch/include/c10d/ProcessGroupNCCL.hpp:    // Same as calling synchronize() for NCCL work.
torch/include/c10d/ProcessGroupNCCL.hpp:    void synchronize() override;
torch/include/c10d/ProcessGroup.hpp:// process groups can be used in parallel and synchronize accordingly.
torch/include/c10d/ProcessGroup.hpp:    virtual void synchronize();
torch/include/torch/csrc/autograd/profiler.h:  virtual void synchronize() {
torch/include/torch/csrc/distributed/c10d/reducer.h:    // so that we can synchronize with them prior to kicking off the reduction.
torch/include/torch/csrc/api/include/torch/data/datasets/chunk.h:      // and evaluating stop_ always happen in a synchronized way
torch/include/torch/csrc/api/include/torch/data/datasets/chunk.h:  // mutex to synchronize chunk sampler next() call.
torch/include/google/protobuf/io/zero_copy_stream_impl.h:  // underlying operating system file object is synchronized to disk.
torch/include/google/protobuf/stubs/common.h:// thread safe, user needs to synchronize multiple calls.
torch/include/google/protobuf/arena.h:// thread must synchronize with users of the arena first.
torch/include/google/protobuf/map_field.h:                                  // synchronized to repeated field
torch/include/google/protobuf/map_field.h:                                  // has not been synchronized to map
torch/include/google/protobuf/map_field.h:  mutable Mutex mutex_;  // The thread to synchronize map and repeated field
torch/include/gloo/cuda_broadcast_one_to_all.h:  const bool synchronizeDeviceOutputs_;
torch/include/gloo/cuda_allreduce_ring_chunked.h:  const bool synchronizeDeviceOutputs_;
torch/include/gloo/cuda.h:  // Get the mutex used to synchronize CUDA and NCCL operations
torch/include/gloo/cuda.h:  // Set the mutex used to synchronize CUDA and NCCL operations
torch/include/gloo/cuda_allreduce_local.h:  const bool synchronizeDeviceOutputs_;
torch/include/gloo/cuda_allreduce_ring.h:  const bool synchronizeDeviceOutputs_;
torch/include/ATen/cuda/CUDAEvent.h:  void synchronize() const {
torch/include/TH/THFile.h:TH_API void THFile_synchronize(THFile *self);
torch/include/TH/THFilePrivate.h:    void (*synchronize)(THFile *self);
torch/include/c10/cuda/CUDAStream.h:* no matter which thread you use it on.  Multiple threads can synchronize
torch/include/c10/cuda/CUDAStream.h:  void synchronize() const {
torch/include/c10/cuda/CUDAStream.h:  // void synchronize_with(const CUDAEvent& event) const;
torch/include/c10/core/impl/DeviceGuardImplInterface.h:// unsynchronized implementation probably is OK too, but I didn't want
torch/include/c10/core/Stream.h: * A stream is a software mechanism used to synchronize launched kernels
torch/include/c10/core/Stream.h: * kernel on the same stream is implicitly synchronized so that if I launch
torch/include/c10/core/Stream.h: * time when the kernels get queued is undetermined unless you synchronize
torch/include/c10/core/DeviceType.h:// This is directly synchronized with caffe2/proto/caffe2.proto, but
torch/include/c10/core/DeviceType.h:// If you modify me, keep me synchronized with that file.
torch/include/caffe2/contrib/shm_mutex/shm_mutex.h: * to synchronize CUDA calls (memory allocation and frees) and
torch/include/caffe2/operators/prefetch_op.h:// the waiting producer after we synchronize). This is a special-case
torch/include/caffe2/core/context_gpu.h:    //   it's preferrable to synchronize in the destructor
torch/include/caffe2/core/event.h:// Prepares context to synchronize device part of operation.
torch/include/caffe2/observers/profile_observer.h: * NOTE: Currently this observer only supports synchronized computation
docs/source/notes/cuda.rst::meth:`~torch.cuda.synchronize` or :meth:`~torch.cuda.Stream.wait_stream`) are
docs/source/notes/multiprocessing.rst:periodically synchronized. In the first case, we recommend sending over the whole
docs/source/bottleneck.rst:    spent executing on a GPU unless the operation does a synchronize.
docs/source/bottleneck.rst:    Ops that do synchronize appear to be extremely expensive under regular
tools/amd_build/build_amd.py:    # Keep this synchronized with is_pytorch_file in hipify_python.py
tools/amd_build/pyHIPIFY/hipify_python.py:# Keep this synchronized with includes/ignores in build_amd.py
Binary file .git/modules/third_party/ideep/modules/mkl-dnn/objects/pack/pack-dc88ba3d809d0eec7faed90a115da19205eaf91c.pack matches
third_party/ideep/mkl-dnn/tests/gtests/gtest/src/gtest-death-test.cc:  // whether previous calls to WaitForMultipleObjects synchronized on this
third_party/eigen/bench/tensors/tensor_benchmarks.h:      device_.synchronize();
third_party/eigen/bench/tensors/tensor_benchmarks.h:      device_.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_sycl.cpp:  sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_sycl.cpp:  sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_sycl.cpp:  sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_sycl.cpp:  sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_sycl.cpp:  sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_sycl.cpp:  sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_sycl.cpp:  sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_sycl.cpp:  sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_sycl.cpp:  sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_sycl.cpp:  sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_reduction_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_reduction_gpu.cu:  dev.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_reduction_gpu.cu:  dev.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_cast_float16_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_of_float16_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_of_float16_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_of_float16_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_of_float16_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_of_float16_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_of_float16_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_of_float16_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_of_float16_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_of_float16_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_complex_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_complex_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_complex_gpu.cu:  gpu_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_device_sycl.cpp:  sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_argmax_sycl.cpp:    sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_argmax_sycl.cpp:    sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_shuffling_sycl.cpp:  sycl_device.synchronize();
third_party/eigen/unsupported/test/cxx11_tensor_shuffling_sycl.cpp:  sycl_device.synchronize();
third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceGpu.h:  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void synchronize() const {
third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:      synchronize();
third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:      synchronize();
third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:    synchronize();
third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:    synchronize();
third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:  EIGEN_STRONG_INLINE void synchronize() const {
third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:  EIGEN_STRONG_INLINE void synchronize() const {
third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:    m_queue_stream->synchronize(); //pass
third_party/tbb/examples/parallel_do/parallel_preorder/parallel_preorder.cpp:            // data races between different tasks, that are actually synchronized.
third_party/tbb/examples/parallel_do/parallel_preorder/readme.html:		between different tasks that are actually synchronized.
third_party/tbb/src/tbb/scheduler.cpp:    to finish. Which means that the local counters may be synchronized earlier (by Thread2,
third_party/tbb/src/tbb/tbb_main.cpp:/* Reading of my_active_value is not synchronized with possible updating
third_party/tbb/src/tbbmalloc/frontend.cpp:        //   on Windows, shutdown is synchronized via loader lock and isMallocInitialized().
third_party/tbb/src/test/test_task_scheduler_observer.cpp:        // when mode is local observation but not synchronized and when num threads == default
third_party/tbb/src/test/test_task_scheduler_observer.cpp:        // when mode is synchronized observation and when num threads == default
third_party/tbb/src/test/test_task_arena.cpp:        // synchronize with other stages
third_party/tbb/src/test/test_concurrent_hash_map.cpp:            // Busy wait to synchronize threads
third_party/tbb/include/tbb/machine/gcc_generic.h:#define __TBB_acquire_consistency_helper()  __sync_synchronize()
third_party/tbb/include/tbb/machine/gcc_generic.h:#define __TBB_release_consistency_helper()  __sync_synchronize()
third_party/tbb/include/tbb/machine/gcc_generic.h:#define __TBB_full_memory_fence()           __sync_synchronize()
third_party/tbb/include/tbb/machine/gcc_generic.h:#define __TBB_control_consistency_helper()  __sync_synchronize()
third_party/cpuinfo/test/dmesg/galaxy-a8-2018.log:[    6.470711] I[0:       iptables: 3201] [SYNC_IPC] abox_synchronized_ipc_handler: TFADSP_CMD_WRITE done
third_party/cpuinfo/test/dmesg/galaxy-a8-2018.log:[    6.482838] I[0:      swapper/0:    0] [SYNC_IPC] abox_synchronized_ipc_handler: TFADSP_CMD_WRITE done
third_party/cpuinfo/test/dmesg/galaxy-a8-2018.log:[    7.485775]  [4:  kworker/u16:2:  241] tfa98xx_monitor(): TDM status: 0x7 (ref. 0x1: synchronized)
third_party/cpuinfo/test/dmesg/galaxy-a8-2018.log:[   12.234361] I[0:    kworker/0:2: 2018] [SYNC_IPC] abox_synchronized_ipc_handler: TFADSP_CMD_WRITE done
third_party/cpuinfo/test/dmesg/galaxy-a8-2018.log:[   12.234629] I[0:    kworker/0:2: 2018] [SYNC_IPC] abox_synchronized_ipc_handler: TFADSP_CMD_READ DONE size= 20
third_party/cpuinfo/src/x86/linux/init.c:	__sync_synchronize();
third_party/cpuinfo/src/x86/mach/init.c:	__sync_synchronize();
third_party/cpuinfo/src/arm/linux/init.c:	__sync_synchronize();
third_party/cpuinfo/src/arm/mach/init.c:	__sync_synchronize();
third_party/gemmlowp/gemmlowp/internal/multi_thread_gemm.h:// pattern, BlockingCounter is used only to synchronize threads after
third_party/foxi/foxi/onnxifi.h: *  - CUDA-based backends could implicitly synchronize with the caller through
third_party/foxi/foxi/onnxifi.h: *  - OpenCL-based backends could implicitly synchronize with the caller through
third_party/pthreadpool/test/pthreadpool.cc:			__sync_synchronize();
third_party/pthreadpool/src/threadpool-pthreads.c:			__sync_synchronize();
third_party/pthreadpool/src/threadpool-pthreads.c:			__sync_synchronize();
third_party/pthreadpool/src/threadpool-pthreads.c:			__sync_synchronize();
third_party/pthreadpool/src/threadpool-pthreads.c:			__sync_synchronize();
third_party/pthreadpool/src/threadpool-pthreads.c:			__sync_synchronize();
third_party/onnx-tensorrt/onnx_tensorrt/tensorrt_engine.py:        self.stream.synchronize()
third_party/onnx-tensorrt/onnx_tensorrt/tensorrt_engine.py:        self.stream.synchronize()
third_party/onnx-tensorrt/third_party/onnx/third_party/pybind11/tools/clang/cindex.py:# Objective-C's @synchronized statement.
third_party/onnx-tensorrt/third_party/onnx/third_party/benchmark/src/cycleclock.h:// clock increments at a constant rate or is synchronized across all logical
third_party/onnx-tensorrt/third_party/onnx/onnx/onnxifi.h: *  - CUDA-based backends could implicitly synchronize with the caller through
third_party/onnx-tensorrt/third_party/onnx/onnx/onnxifi.h: *  - OpenCL-based backends could implicitly synchronize with the caller through
third_party/FP16/third-party/half.hpp:/// to synchronize the rounding mode with that of the underlying single-precision implementation.
third_party/protobuf/objectivec/GPBDescriptor.m:  @synchronized(self) {
third_party/protobuf/third_party/googletest/googletest/src/gtest-death-test.cc:  // whether previous calls to WaitForMultipleObjects synchronized on this
third_party/protobuf/third_party/benchmark/src/cycleclock.h:// clock increments at a constant rate or is synchronized across all logical
third_party/protobuf/java/core/src/main/java/com/google/protobuf/CodedOutputStream.java: * <p>This class is totally unsynchronized.
third_party/protobuf/java/core/src/main/java/com/google/protobuf/LazyStringArrayList.java: * <strong>Note that this implementation is not synchronized.</strong>
third_party/protobuf/java/core/src/main/java/com/google/protobuf/LazyStringArrayList.java: * <i>must</i> be synchronized externally.  (A structural modification is
third_party/protobuf/java/core/src/main/java/com/google/protobuf/RopeByteString.java:    public synchronized void reset() {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/GeneratedMessageV3.java:      synchronized (this) {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/LazyFieldLite.java:    synchronized (this) {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/LazyFieldLite.java:    synchronized (this) {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/Descriptors.java:      synchronized (this) {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/GeneratedMessage.java:        synchronized (this) {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/GeneratedMessage.java:      synchronized (this) {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/MapField.java: * all access must be synchronized.
third_party/protobuf/java/core/src/main/java/com/google/protobuf/MapField.java:      synchronized (this) {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/MapField.java:      synchronized (this) {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/RpcUtil.java:        synchronized (this) {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java:    // The public methods of this class must be synchronized.  ByteStrings
third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java:    public synchronized void write(int b) {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java:    public synchronized void write(byte[] b, int offset, int length)  {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java:    public synchronized ByteString toByteString() {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java:      synchronized (this) {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java:    public synchronized int size() {
third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java:    public synchronized void reset() {
third_party/protobuf/java/core/src/test/java/com/google/protobuf/CodedInputStreamTest.java:          public synchronized int available() {
third_party/protobuf/java/core/src/test/java/com/google/protobuf/CodedInputStreamTest.java:          public synchronized int available() {
third_party/protobuf/src/google/protobuf/io/zero_copy_stream_impl.h:  // underlying operating system file object is synchronized to disk.
third_party/protobuf/src/google/protobuf/arena.cc:  // properly synchronize Reset() or the destructor will throw a TSAN warning.
third_party/protobuf/src/google/protobuf/arena.cc:  // properly synchronize Reset() or the destructor will throw a TSAN warning.
third_party/protobuf/src/google/protobuf/stubs/common.h:// thread safe, user needs to synchronize multiple calls.
third_party/protobuf/src/google/protobuf/arena.h:// thread must synchronize with users of the arena first.
third_party/protobuf/src/google/protobuf/map_field.h:                                  // synchronized to repeated field
third_party/protobuf/src/google/protobuf/map_field.h:                                  // has not been synchronized to map
third_party/protobuf/src/google/protobuf/map_field.h:  mutable Mutex mutex_;  // The thread to synchronize map and repeated field
third_party/protobuf/src/google/protobuf/compiler/js/js_generator.cc:  "synchronized",
third_party/protobuf/src/google/protobuf/compiler/java/java_message_lite.cc:    "    synchronized ($classname$.class) {\n"
third_party/pybind11/tools/clang/cindex.py:# Objective-C's @synchronized statement.
third_party/fbgemm/third_party/cpuinfo/test/dmesg/galaxy-a8-2018.log:[    6.470711] I[0:       iptables: 3201] [SYNC_IPC] abox_synchronized_ipc_handler: TFADSP_CMD_WRITE done
third_party/fbgemm/third_party/cpuinfo/test/dmesg/galaxy-a8-2018.log:[    6.482838] I[0:      swapper/0:    0] [SYNC_IPC] abox_synchronized_ipc_handler: TFADSP_CMD_WRITE done
third_party/fbgemm/third_party/cpuinfo/test/dmesg/galaxy-a8-2018.log:[    7.485775]  [4:  kworker/u16:2:  241] tfa98xx_monitor(): TDM status: 0x7 (ref. 0x1: synchronized)
third_party/fbgemm/third_party/cpuinfo/test/dmesg/galaxy-a8-2018.log:[   12.234361] I[0:    kworker/0:2: 2018] [SYNC_IPC] abox_synchronized_ipc_handler: TFADSP_CMD_WRITE done
third_party/fbgemm/third_party/cpuinfo/test/dmesg/galaxy-a8-2018.log:[   12.234629] I[0:    kworker/0:2: 2018] [SYNC_IPC] abox_synchronized_ipc_handler: TFADSP_CMD_READ DONE size= 20
third_party/fbgemm/third_party/cpuinfo/src/x86/linux/init.c:	__sync_synchronize();
third_party/fbgemm/third_party/cpuinfo/src/x86/mach/init.c:	__sync_synchronize();
third_party/fbgemm/third_party/cpuinfo/src/arm/linux/init.c:	__sync_synchronize();
third_party/fbgemm/third_party/cpuinfo/src/arm/mach/init.c:	__sync_synchronize();
third_party/fbgemm/third_party/googletest/googletest/src/gtest-death-test.cc:  // whether previous calls to WaitForMultipleObjects synchronized on this
third_party/gloo/docs/cuda.md:* Ensure the GPU buffer inputs are synchronized and valid, or
third_party/gloo/docs/cuda.md:If no `cudaStream_t`(s) are passed to the gloo collective function, GPU buffer outputs are valid when the gloo collective function returns. Otherwise, the calling code must synchronize with the streams before using the GPU buffer outputs, i.e., explicitly with `cudaStreamSynchronize()` or inserting dependent operations in the stream.
third_party/gloo/docs/cuda.md:// Define a mutex to synchronize calls to cudaMalloc/cudaFree
third_party/gloo/gloo/cuda_allreduce_local.cc:      synchronizeDeviceOutputs_(streams.size() == 0) {
third_party/gloo/gloo/cuda_allreduce_local.cc:    if (synchronizeDeviceOutputs_) {
third_party/gloo/gloo/cuda_allreduce_ring.cc:      synchronizeDeviceOutputs_(streams.size() == 0),
third_party/gloo/gloo/cuda_allreduce_ring.cc:    if (synchronizeDeviceOutputs_) {
third_party/gloo/gloo/cuda_broadcast_one_to_all.h:  const bool synchronizeDeviceOutputs_;
third_party/gloo/gloo/cuda_allreduce_ring_chunked.cc:      synchronizeDeviceOutputs_(streams.size() == 0),
third_party/gloo/gloo/cuda_allreduce_ring_chunked.cc:  if (synchronizeDeviceOutputs_) {
third_party/gloo/gloo/cuda.cu:// Default mutex to synchronize contentious CUDA and NCCL operations
third_party/gloo/gloo/cuda.cu:  // Create new event to synchronize operations against
third_party/gloo/gloo/cuda_allreduce_ring_chunked.h:  const bool synchronizeDeviceOutputs_;
third_party/gloo/gloo/cuda.h:  // Get the mutex used to synchronize CUDA and NCCL operations
third_party/gloo/gloo/cuda.h:  // Set the mutex used to synchronize CUDA and NCCL operations
third_party/gloo/gloo/cuda_broadcast_one_to_all.cc:      synchronizeDeviceOutputs_(streams.size() == 0) {
third_party/gloo/gloo/cuda_broadcast_one_to_all.cc:      if (synchronizeDeviceOutputs_) {
third_party/gloo/gloo/cuda_broadcast_one_to_all.cc:      if (synchronizeDeviceOutputs_) {
third_party/gloo/gloo/cuda_broadcast_one_to_all.cc:      // Since broadcast synchronizes on root pointer, there is no
third_party/gloo/gloo/cuda_broadcast_one_to_all.cc:      if (synchronizeDeviceOutputs_) {
third_party/gloo/gloo/cuda_broadcast_one_to_all.cc:      if (synchronizeDeviceOutputs_) {
third_party/gloo/gloo/allgather.cc:    // Wait for pending operations to complete to synchronize with the
third_party/gloo/gloo/test/cuda_broadcast_test.cc:          fixture.synchronizeCudaStreams();
third_party/gloo/gloo/test/cuda_allreduce_test.cc:      fixture.synchronizeCudaStreams();
third_party/gloo/gloo/test/barrier_test.cc:    // Run barrier to synchronize processes after starting.
third_party/gloo/gloo/test/cuda_base_test.h:    synchronizeCudaStreams();
third_party/gloo/gloo/test/cuda_base_test.h:  void synchronizeCudaStreams() {
third_party/gloo/gloo/cuda_allreduce_local.h:  const bool synchronizeDeviceOutputs_;
third_party/gloo/gloo/nccl/nccl.cu:  // Allocate events to synchronize source, destination, and NCCL streams
third_party/gloo/gloo/cuda_allreduce_ring.h:  const bool synchronizeDeviceOutputs_;
third_party/gloo/gloo/benchmark/runner.cc:  // Create broadcast algorithm to synchronize between participants
third_party/gloo/gloo/benchmark/runner.cc:    // Start jobs on every thread (synchronized across processes)
third_party/gloo/gloo/benchmark/runner.cc:  // Start jobs on every thread (synchronized across processes)
third_party/cub/cub/host/mutex.cuh:            __sync_synchronize();
third_party/cub/cub/block/block_exchange.cuh: * \tparam WARP_TIME_SLICING    <b>[optional]</b> When \p true, only use enough shared memory for a single warp's worth of tile data, time-slicing the block-wide exchange over multiple synchronized rounds.  Yields a smaller memory footprint at the expense of decreased parallelism.  (Default: false)
third_party/cub/cub/device/dispatch/dispatch_reduce.cuh:    bool                debug_synchronous;              ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_reduce.cuh:        bool            debug_synchronous)                  ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_reduce.cuh:    bool                debug_synchronous;      ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_reduce.cuh:        bool            debug_synchronous)                  ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_radix_sort.cuh:    bool                    debug_synchronous;      ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_radix_sort.cuh:        bool                    debug_synchronous)      ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_radix_sort.cuh:    bool                    debug_synchronous;      ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_radix_sort.cuh:        bool                    debug_synchronous)      ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_histogram.cuh:        bool                                debug_synchronous)                              ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_histogram.cuh:        bool                debug_synchronous,                          ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_histogram.cuh:        bool                debug_synchronous,                          ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_histogram.cuh:        bool                debug_synchronous,                          ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_histogram.cuh:        bool                debug_synchronous,                          ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_scan.cuh:        bool                debug_synchronous,      ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_scan.cuh:        bool            debug_synchronous)      ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_select_if.cuh:        bool                        debug_synchronous,              ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_select_if.cuh:        bool                        debug_synchronous)              ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_reduce_by_key.cuh:        bool                        debug_synchronous,          ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_reduce_by_key.cuh:        bool                        debug_synchronous)              ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_spmv_orig.cuh:        bool                    debug_synchronous,                  ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_spmv_orig.cuh:        bool                    debug_synchronous       = false)    ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_rle.cuh:        bool                        debug_synchronous,              ///< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/dispatch/dispatch_rle.cuh:        bool                        debug_synchronous)              ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_radix_sort.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_radix_sort.cuh:        bool                    debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_radix_sort.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_radix_sort.cuh:        bool                    debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_radix_sort.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_radix_sort.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_radix_sort.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_radix_sort.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_scan.cuh:        bool            debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_scan.cuh:        bool            debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_scan.cuh:        bool                debug_synchronous  = false)     ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_scan.cuh:        bool            debug_synchronous  = false)         ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_histogram.cuh:        bool                debug_synchronous       = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_histogram.cuh:        bool                debug_synchronous       = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_histogram.cuh:        bool                debug_synchronous       = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_histogram.cuh:        bool                debug_synchronous       = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_histogram.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_histogram.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_histogram.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_histogram.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_segmented_reduce.cuh:        bool                debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_segmented_reduce.cuh:        bool                debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_segmented_reduce.cuh:        bool                debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_segmented_reduce.cuh:        bool                debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_segmented_reduce.cuh:        bool                debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_segmented_reduce.cuh:        bool                debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_run_length_encode.cuh:        bool                        debug_synchronous  = false)     ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_run_length_encode.cuh:        bool                    debug_synchronous  = false)     ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_select.cuh:        bool                        debug_synchronous  = false)     ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_select.cuh:        bool                        debug_synchronous  = false)     ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_select.cuh:        bool                        debug_synchronous  = false)     ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_reduce.cuh:        bool                        debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_reduce.cuh:        bool                        debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_reduce.cuh:        bool                        debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_reduce.cuh:        bool                        debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_reduce.cuh:        bool                        debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_reduce.cuh:        bool                        debug_synchronous   = false)        ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_reduce.cuh:        bool                        debug_synchronous  = false)     ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_segmented_radix_sort.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_segmented_radix_sort.cuh:        bool                    debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_segmented_radix_sort.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_segmented_radix_sort.cuh:        bool                    debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_segmented_radix_sort.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_segmented_radix_sort.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_segmented_radix_sort.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_segmented_radix_sort.cuh:        bool                debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/cub/device/device_spmv.cuh:        bool                debug_synchronous       = false)    ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_partition.cuh:        bool                        debug_synchronous  = false)     ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/device/device_partition.cuh:        bool                        debug_synchronous  = false)     ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  May cause significant slowdown.  Default is \p false.
third_party/cub/cub/util_allocator.cuh:                    // blocking and will synchronize across all kernels executing
third_party/cub/experimental/defunct/test_device_seg_reduce.cu:        bool                            debug_synchronous,                      ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/experimental/defunct/test_device_seg_reduce.cu:        bool                            debug_synchronous)                      ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/experimental/defunct/test_device_seg_reduce.cu:        bool                    debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/cub/experimental/defunct/test_device_seg_reduce.cu:        bool                    debug_synchronous   = false)            ///< [in] <b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \p false.
third_party/nccl/nccl/src/transport/net.cc:                __sync_synchronize();
third_party/nccl/nccl/src/transport/net.cc:            __sync_synchronize();
third_party/nccl/nccl/src/transport/net_ib.cc:  __sync_synchronize(); // order the readyPtr load against rkey load below
third_party/nccl/nccl/src/transport/net_ib.cc:  __sync_synchronize();
third_party/googletest/googletest/src/gtest-death-test.cc:  // whether previous calls to WaitForMultipleObjects synchronized on this
third_party/onnx/third_party/pybind11/tools/clang/cindex.py:# Objective-C's @synchronized statement.
third_party/onnx/third_party/benchmark/src/cycleclock.h:// clock increments at a constant rate or is synchronized across all logical
third_party/onnx/onnx/onnxifi.h: *  - CUDA-based backends could implicitly synchronize with the caller through
third_party/onnx/onnx/onnxifi.h: *  - OpenCL-based backends could implicitly synchronize with the caller through
third_party/zstd/tests/zbufftest.c:        /* states full reset (unsynchronized) */
third_party/zstd/tests/zstreamtest.c:        /* states full reset (deliberately not synchronized) */
third_party/zstd/tests/zstreamtest.c:        /* states full reset (deliberately not synchronized) */
third_party/zstd/tests/zstreamtest.c:        /* states full reset (deliberately not synchronized) */
third_party/zstd/programs/zstdcli.c:    unsigned bench_nbSeconds = 3;   /* would be better if this value was synchronized from bench */
third_party/zstd/lib/legacy/zstd_v01.c:    for ( ; (reloadStatus<FSE_DStream_completed) && (op<olimit);  /* D2-3-4 are supposed to be synchronized and finish together */
third_party/benchmark/src/cycleclock.h:// clock increments at a constant rate or is synchronized across all logical
aten/src/ATen/cuda/CUDAEvent.h:  void synchronize() const {
aten/src/ATen/hip/impl/HIPStreamMasqueradingAsCUDA.h:  void synchronize() const   { stream_.synchronize(); }
aten/src/ATen/native/LinearAlgebra.cpp:  // This synchronizes on GPU, but `_lu_det_P_diag_U_info` above already synchronizes
aten/src/ATen/native/cuda/Copy.cu:  // on the source device, and we fully synchronize on both src and dst's
aten/src/ATen/native/cuda/SummaryOps.cu:    //   Atomic update is imp since __syncthread() will only synchronize threads
aten/src/ATen/native/cuda/SummaryOps.cu:    //   Atomic update is imp since __syncthread() will only synchronize threads
aten/src/ATen/native/Normalization.cpp:// XXX: The indices of backends need to be kept synchronized between this function and its _backward.
aten/src/ATen/native/cudnn/RNN.cpp:  // Every time we use a dropout state, we need to synchronize with its event,
aten/src/ATen/native/cudnn/RNN.cpp:  // we're done, we record the event to allow others to synchronize with this kernel.
aten/src/TH/THFile.h:TH_API void THFile_synchronize(THFile *self);
aten/src/TH/THFilePrivate.h:    void (*synchronize)(THFile *self);
aten/src/TH/THFile.cpp:void THFile_synchronize(THFile *self)
aten/src/TH/THFile.cpp:  self->vtable->synchronize(self);
aten/src/TH/THDiskFile.cpp:static void THDiskFile_synchronize(THFile *self)
aten/src/TH/THDiskFile.cpp:    THDiskFile_synchronize,
aten/src/TH/THDiskFile.cpp:    THDiskFile_synchronize,
aten/src/TH/THMemoryFile.cpp:static void THMemoryFile_synchronize(THFile *self)
aten/src/TH/THMemoryFile.cpp:    THMemoryFile_synchronize,
Binary file build/test_api/CMakeFiles/test_api.dir/parallel.cpp.o matches
Binary file build/modules/detectron/CMakeFiles/caffe2_detectron_ops_gpu.dir/caffe2_detectron_ops_gpu_generated_ps_roi_pool_op.cu.o matches
Binary file build/modules/detectron/CMakeFiles/caffe2_detectron_ops_gpu.dir/caffe2_detectron_ops_gpu_generated_group_spatial_softmax_op.cu.o matches
Binary file build/modules/detectron/CMakeFiles/caffe2_detectron_ops_gpu.dir/caffe2_detectron_ops_gpu_generated_roi_pool_f_op.cu.o matches
Binary file build/modules/detectron/CMakeFiles/caffe2_detectron_ops_gpu.dir/caffe2_detectron_ops_gpu_generated_select_smooth_l1_loss_op.cu.o matches
Binary file build/modules/detectron/CMakeFiles/caffe2_detectron_ops_gpu.dir/caffe2_detectron_ops_gpu_generated_spatial_narrow_as_op.cu.o matches
Binary file build/modules/detectron/CMakeFiles/caffe2_detectron_ops_gpu.dir/caffe2_detectron_ops_gpu_generated_sigmoid_focal_loss_op.cu.o matches
Binary file build/modules/detectron/CMakeFiles/caffe2_detectron_ops_gpu.dir/caffe2_detectron_ops_gpu_generated_sample_as_op.cu.o matches
Binary file build/modules/detectron/CMakeFiles/caffe2_detectron_ops_gpu.dir/caffe2_detectron_ops_gpu_generated_sigmoid_cross_entropy_loss_op.cu.o matches
Binary file build/modules/detectron/CMakeFiles/caffe2_detectron_ops_gpu.dir/caffe2_detectron_ops_gpu_generated_smooth_l1_loss_op.cu.o matches
Binary file build/modules/detectron/CMakeFiles/caffe2_detectron_ops_gpu.dir/caffe2_detectron_ops_gpu_generated_softmax_focal_loss_op.cu.o matches
Binary file build/modules/detectron/CMakeFiles/caffe2_detectron_ops_gpu.dir/caffe2_detectron_ops_gpu_generated_batch_permutation_op.cu.o matches
Binary file build/modules/detectron/CMakeFiles/caffe2_detectron_ops_gpu.dir/caffe2_detectron_ops_gpu_generated_upsample_nearest_op.cu.o matches
Binary file build/bin/net_gpu_test matches
Binary file build/bin/test_api matches
Binary file build/bin/protoc matches
Binary file build/bin/utility_ops_gpu_test matches
Binary file build/bin/context_gpu_test matches
Binary file build/bin/mpi_gpu_test matches
Binary file build/bin/operator_gpu_test matches
Binary file build/bin/batch_matmul_op_gpu_test matches
Binary file build/bin/operator_fallback_gpu_test matches
Binary file build/bin/generate_proposals_op_util_nms_gpu_test matches
Binary file build/bin/cuda_tensor_interop_test matches
Binary file build/bin/blob_gpu_test matches
Binary file build/bin/event_gpu_test matches
Binary file build/bin/math_gpu_test matches
Binary file build/bin/ProcessGroupMPITest matches
Binary file build/bin/roi_align_op_gpu_test matches
Binary file build/bin/ProcessGroupGlooAsyncTest matches
Binary file build/bin/generate_proposals_op_gpu_test matches
Binary file build/bin/cuda_packedtensoraccessor_test matches
Binary file build/bin/ProcessGroupGlooTest matches
Binary file build/bin/elementwise_op_gpu_test matches
Binary file build/bin/ProcessGroupNCCLTest matches
Binary file build/bin/reshape_op_gpu_test matches
Binary file build/bin/cuda_stream_test matches
Binary file build/third_party/protobuf/cmake/CMakeFiles/libprotoc.dir/__/src/google/protobuf/compiler/js/js_generator.cc.o matches
Binary file build/third_party/protobuf/cmake/CMakeFiles/libprotoc.dir/__/src/google/protobuf/compiler/java/java_message_lite.cc.o matches
Binary file build/third_party/gloo/gloo/CMakeFiles/gloo_cuda.dir/cuda_allreduce_ring.cc.o matches
Binary file build/third_party/gloo/gloo/CMakeFiles/gloo_cuda.dir/cuda_allreduce_local.cc.o matches
Binary file build/third_party/gloo/gloo/CMakeFiles/gloo_cuda.dir/cuda_allreduce_ring_chunked.cc.o matches
Binary file build/third_party/gloo/gloo/CMakeFiles/gloo_cuda.dir/cuda_broadcast_one_to_all.cc.o matches
Binary file build/c10/cuda/CMakeFiles/c10_cuda.dir/impl/CUDAGuardImpl.cpp.o matches
Binary file build/c10/cuda/CMakeFiles/c10_cuda.dir/CUDACachingAllocator.cpp.o matches
Binary file build/c10/cuda/CMakeFiles/c10_cuda.dir/CUDAStream.cpp.o matches
Binary file build/lib/libc10_cuda.so matches
Binary file build/lib/libgloo_cuda.a matches
Binary file build/lib/libc10d_cuda_test.so matches
Binary file build/lib/libtorch_python.so matches
Binary file build/lib/libcaffe2_detectron_ops_gpu.so matches
Binary file build/lib/libprotocd.a matches
Binary file build/lib/libc10d.a matches
Binary file build/lib/libtorch.so matches
build/lib.linux-x86_64-3.7/torch/autograd/profiler.py:        torch.cuda.synchronize()
build/lib.linux-x86_64-3.7/torch/autograd/profiler.py:        torch.cuda.synchronize()
build/lib.linux-x86_64-3.7/torch/jit/__init__.py:        end.synchronize()
build/lib.linux-x86_64-3.7/torch/cuda/__init__.pyi:def synchronize(device: _device_t) -> None: ...
build/lib.linux-x86_64-3.7/torch/cuda/__init__.py:def synchronize(device=None):
build/lib.linux-x86_64-3.7/torch/cuda/__init__.py:        device (torch.device or int, optional): device for which to synchronize.
build/lib.linux-x86_64-3.7/torch/cuda/__init__.py:        return torch._C._cuda_synchronize()
build/lib.linux-x86_64-3.7/torch/cuda/streams.py:            stream (Stream): a stream to synchronize.
build/lib.linux-x86_64-3.7/torch/cuda/streams.py:    def synchronize(self):
build/lib.linux-x86_64-3.7/torch/cuda/streams.py:        super(Stream, self).synchronize()
build/lib.linux-x86_64-3.7/torch/cuda/streams.py:    device's progress, to accurately measure timing, and to synchronize CUDA
build/lib.linux-x86_64-3.7/torch/cuda/streams.py:    def synchronize(self):
build/lib.linux-x86_64-3.7/torch/cuda/streams.py:        super(Event, self).synchronize()
Binary file build/lib.linux-x86_64-3.7/torch/bin/test_api matches
Binary file build/lib.linux-x86_64-3.7/torch/bin/protoc matches
build/lib.linux-x86_64-3.7/torch/nn/parallel/distributed.py:        variables, which will later be synchronized in the first
build/lib.linux-x86_64-3.7/torch/nn/parallel/distributed.py:            ... ddp(another_input).backward()  # synchronize grads
Binary file build/lib.linux-x86_64-3.7/torch/test/net_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/utility_ops_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/context_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/mpi_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/operator_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/batch_matmul_op_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/operator_fallback_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/generate_proposals_op_util_nms_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/cuda_tensor_interop_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/blob_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/event_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/math_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/roi_align_op_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/generate_proposals_op_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/cuda_packedtensoraccessor_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/elementwise_op_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/reshape_op_gpu_test matches
Binary file build/lib.linux-x86_64-3.7/torch/test/cuda_stream_test matches
Binary file build/lib.linux-x86_64-3.7/torch/lib/libc10_cuda.so matches
Binary file build/lib.linux-x86_64-3.7/torch/lib/libtorch_python.so matches
Binary file build/lib.linux-x86_64-3.7/torch/lib/libcaffe2_detectron_ops_gpu.so matches
Binary file build/lib.linux-x86_64-3.7/torch/lib/libtorch.so matches
build/lib.linux-x86_64-3.7/torch/include/torch/csrc/autograd/profiler.h:  virtual void synchronize() {
build/lib.linux-x86_64-3.7/torch/include/torch/csrc/api/include/torch/data/datasets/chunk.h:      // and evaluating stop_ always happen in a synchronized way
build/lib.linux-x86_64-3.7/torch/include/torch/csrc/api/include/torch/data/datasets/chunk.h:  // mutex to synchronize chunk sampler next() call.
build/lib.linux-x86_64-3.7/torch/include/ATen/cuda/CUDAEvent.h:  void synchronize() const {
build/lib.linux-x86_64-3.7/torch/include/TH/THFile.h:TH_API void THFile_synchronize(THFile *self);
build/lib.linux-x86_64-3.7/torch/include/TH/THFilePrivate.h:    void (*synchronize)(THFile *self);
build/lib.linux-x86_64-3.7/torch/include/c10/cuda/CUDAStream.h:* no matter which thread you use it on.  Multiple threads can synchronize
build/lib.linux-x86_64-3.7/torch/include/c10/cuda/CUDAStream.h:  void synchronize() const {
build/lib.linux-x86_64-3.7/torch/include/c10/cuda/CUDAStream.h:  // void synchronize_with(const CUDAEvent& event) const;
build/lib.linux-x86_64-3.7/torch/include/c10/core/impl/DeviceGuardImplInterface.h:// unsynchronized implementation probably is OK too, but I didn't want
build/lib.linux-x86_64-3.7/torch/include/c10/core/Stream.h: * A stream is a software mechanism used to synchronize launched kernels
build/lib.linux-x86_64-3.7/torch/include/c10/core/Stream.h: * kernel on the same stream is implicitly synchronized so that if I launch
build/lib.linux-x86_64-3.7/torch/include/c10/core/Stream.h: * time when the kernels get queued is undetermined unless you synchronize
build/lib.linux-x86_64-3.7/torch/include/c10/core/DeviceType.h:// This is directly synchronized with caffe2/proto/caffe2.proto, but
build/lib.linux-x86_64-3.7/torch/include/c10/core/DeviceType.h:// If you modify me, keep me synchronized with that file.
build/lib.linux-x86_64-3.7/torch/include/caffe2/operators/prefetch_op.h:// the waiting producer after we synchronize). This is a special-case
build/lib.linux-x86_64-3.7/torch/include/caffe2/core/context_gpu.h:    //   it's preferrable to synchronize in the destructor
build/lib.linux-x86_64-3.7/torch/include/caffe2/core/event.h:// Prepares context to synchronize device part of operation.
build/lib.linux-x86_64-3.7/torch/include/caffe2/observers/profile_observer.h: * NOTE: Currently this observer only supports synchronized computation
build/lib.linux-x86_64-3.7/caffe2/contrib/gloo/gloo_test.py:    def synchronize(self, store_handler, value, comm_rank=None):
build/lib.linux-x86_64-3.7/caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
build/lib.linux-x86_64-3.7/caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
build/lib.linux-x86_64-3.7/caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
build/lib.linux-x86_64-3.7/caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
build/lib.linux-x86_64-3.7/caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
build/lib.linux-x86_64-3.7/caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
build/lib.linux-x86_64-3.7/caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
build/lib.linux-x86_64-3.7/caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
Binary file build/lib.linux-x86_64-3.7/caffe2/python/caffe2_pybind11_state_gpu.cpython-37m-x86_64-linux-gnu.so matches
build/lib.linux-x86_64-3.7/caffe2/python/data_parallel_model.py:                        to synchronize shards before a training epoch starts.
build/lib.linux-x86_64-3.7/caffe2/python/data_parallel_model.py:    # synchronized values by the training net
build/caffe2/contrib/gloo/gloo_test.py:    def synchronize(self, store_handler, value, comm_rank=None):
build/caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
build/caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
build/caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
build/caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
build/caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
build/caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
build/caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
build/caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/autograd/generated/python_variable_methods.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/distributed/c10d/ddp.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/distributed/c10d/init.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/cuda/Module.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/cuda/Event.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/cuda/nccl.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/cuda/utils.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/cuda/python_nccl.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/cuda/Stream.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/cuda/serialization.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/cuda/Storage.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/cuda/python_comm.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/nn/THCUNN.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/nn/THNN.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/Storage.cpp.o matches
Binary file build/caffe2/torch/CMakeFiles/torch_python.dir/csrc/CudaIPCTypes.cpp.o matches
Binary file build/caffe2/python/caffe2_pybind11_state_gpu.cpython-37m-x86_64-linux-gnu.so matches
build/caffe2/python/data_parallel_model.py:                        to synchronize shards before a training epoch starts.
build/caffe2/python/data_parallel_model.py:    # synchronized values by the training net
Binary file build/caffe2/lib_c10d/test/CMakeFiles/ProcessGroupGlooAsyncTest.dir/ProcessGroupGlooAsyncTest.cpp.o matches
Binary file build/caffe2/lib_c10d/test/CMakeFiles/ProcessGroupNCCLTest.dir/ProcessGroupNCCLTest.cpp.o matches
Binary file build/caffe2/lib_c10d/test/CMakeFiles/c10d_cuda_test.dir/c10d_cuda_test_generated_CUDATest.cu.o matches
Binary file build/caffe2/lib_c10d/CMakeFiles/c10d.dir/ProcessGroup.cpp.o matches
Binary file build/caffe2/lib_c10d/CMakeFiles/c10d.dir/ProcessGroupNCCL.cpp.o matches
Binary file build/caffe2/lib_c10d/CMakeFiles/c10d.dir/ProcessGroupGloo.cpp.o matches
Binary file build/caffe2/lib_c10d/CMakeFiles/c10d.dir/ProcessGroupMPI.cpp.o matches
Binary file build/caffe2/CMakeFiles/context_gpu_test.dir/core/context_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/operator_fallback_gpu_test.dir/operators/operator_fallback_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/elementwise_op_gpu_test.dir/operators/elementwise_op_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/generate_proposals_op_util_nms_gpu_test.dir/operators/generate_proposals_op_util_nms_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/generate_proposals_op_gpu_test.dir/operators/generate_proposals_op_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/math_gpu_test.dir/utils/math_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/utility_ops_gpu_test.dir/operators/utility_ops_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/event_gpu_test.dir/core/event_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/blob_gpu_test.dir/core/blob_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/cuda_packedtensoraccessor_test.dir/__/aten/src/ATen/test/cuda_packedtensoraccessor_test_generated_cuda_packedtensoraccessor_test.cu.o matches
Binary file build/caffe2/CMakeFiles/batch_matmul_op_gpu_test.dir/operators/batch_matmul_op_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/cuda_stream_test.dir/__/aten/src/ATen/test/cuda_stream_test.cpp.o matches
Binary file build/caffe2/CMakeFiles/operator_gpu_test.dir/core/operator_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/mpi_gpu_test.dir/mpi/mpi_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/roi_align_op_gpu_test.dir/operators/roi_align_op_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/caffe2_pybind11_state_gpu.dir/python/pybind_state_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/cuda_tensor_interop_test.dir/__/aten/src/ATen/test/cuda_tensor_interop_test.cpp.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/utils/torch_generated_math_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/utils/math/torch_generated_transpose.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/utils/math/torch_generated_reduce.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/utils/math/torch_generated_elementwise.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/utils/math/torch_generated_broadcast.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/torch/csrc/autograd/profiler_cuda.cpp.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/torch/csrc/autograd/functions/comm.cpp.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/torch/csrc/autograd/profiler.cpp.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/torch/csrc/jit/fuser/cuda/fused_kernel.cpp.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/torch/csrc/cuda/comm.cpp.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/torch_generated_THCTensorMathScan.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/THCTensor.cpp.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/torch_generated_THCStorage.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/torch_generated_THCTensorMode.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorSortByte.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorSortChar.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorMaskedChar.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorSortDouble.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorMaskedHalf.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorSortFloat.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorSortHalf.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorSortInt.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorMathReduceDouble.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorMaskedBool.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorMaskedByte.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorMaskedLong.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorSortLong.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorMaskedShort.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorMaskedDouble.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorMathReduceHalf.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorMaskedFloat.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorMaskedInt.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorSortShort.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/generated/torch_generated_THCTensorMathReduceFloat.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/torch_generated_THCTensorMath.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/THCCachingHostAllocator.cpp.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THC/torch_generated_THCTensorIndex.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THCUNN/torch_generated_L1Cost.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THCUNN/torch_generated_SmoothL1Criterion.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THCUNN/torch_generated_MarginCriterion.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THCUNN/torch_generated_MSECriterion.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THCUNN/torch_generated_LookupTable.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THCUNN/torch_generated_LookupTableBag.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THCUNN/torch_generated_DistKLDivCriterion.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THCUNN/torch_generated_SoftMarginCriterion.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THCUNN/torch_generated_AbsCriterion.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/THCUNN/torch_generated_BCECriterion.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/sparse/cuda/torch_generated_SparseCUDATensor.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/sparse/cuda/torch_generated_SparseCUDABlas.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/sparse/cuda/torch_generated_SparseCUDATensorMath.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_DilatedMaxPool2d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_ReduceOpsKernel.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_AdaptiveAveragePooling3d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_EmbeddingBag.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_FractionalMaxPool2d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_AveragePool3d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_AveragePool2d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_DilatedConvolution.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_MaxUnpooling.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_SummaryOps.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_FractionalMaxPool3d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_Indexing.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_SoftMax.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_FillKernel.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_RangeFactories.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_UpSampleBilinear2d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_WeightNorm.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_Copy.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_Distributions.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_BinaryOpsKernel.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_TensorTransformations.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_TensorFactories.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_EmbeddingBackwardKernel.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_Normalization.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_Embedding.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_Resize.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_Loss.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_ConvolutionTranspose2d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_ReplicationPadding.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_AdaptiveMaxPooling3d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_ConvolutionTranspose3d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_IndexKernel.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_LossCTC.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_Dropout.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_UpSampleNearest1d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_AdaptiveMaxPooling2d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_Unique.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_ReflectionPad.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_AdaptiveAveragePooling.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_UpSampleNearest3d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_Col2Im.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_CUDAScalar.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_UnaryOpsKernel.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_UpSampleNearest2d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_SortingKthValue.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_TensorCompare.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_UpSampleBicubic2d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_DilatedMaxPool3d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_BatchLinearAlgebra.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_Im2Col.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_RNN.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_Activation.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_Lerp.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_GridSampler.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_UpSampleLinear1d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_SpectralOps.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/cuda/torch_generated_UpSampleTrilinear3d.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/ATen/native/quantized/cuda/torch_generated_fake_quantize_per_tensor_affine.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/TH/THDiskFile.cpp.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/TH/THFile.cpp.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/__/aten/src/TH/THMemoryFile.cpp.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/contrib/gloo/broadcast_ops_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/contrib/gloo/allreduce_ops_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/contrib/gloo/common_world_ops_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/contrib/aten/aten_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/contrib/nccl/cuda_nccl_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/contrib/nccl/cuda_nccl_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/distributed/file_store_handler_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_cosine_embedding_criterion_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/sqrt_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_filler_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_sparse_to_dense_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_rsqrt_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_reduce_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_find_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_rmac_regions_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_glu_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_utility_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_cosh_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_batch_moments_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_reduce_front_back_sum_mean_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_data_couple_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_gelu_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/counter_ops_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/prepend_dim_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/elementwise_add_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/expand_squeeze_dims_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_reverse_packed_segs_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_perplexity_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_max_pool_with_index.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_elementwise_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/conv_op_shared_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/matmul_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_floor_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_lengths_pad_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_sinh_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_integral_image_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_reciprocal_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_channel_shuffle_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/conv_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_boolean_unmask_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_ensure_cpu_output_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/im2col_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_hard_sigmoid_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_cast_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_lstm_unit_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_relu_n_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_batch_matmul_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_roi_align_rotated_gradient_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_elementwise_mul_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_one_hot_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/stop_gradient_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_affine_channel_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_assert_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_erf_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_pool_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_lp_pool_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_logit_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_roi_align_rotated_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_group_norm_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/sqr_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_asin_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_sparse_normalize_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_channel_backprop_stats_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/order_switch_ops_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_reduce_front_back_max_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_softmax_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/exp_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_unique_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/fully_connected_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_accumulate_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_leaky_relu_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_local_response_normalization_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_mean_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_pack_segments.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_cos_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_half_float_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/conv_transpose_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_top_k.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_elu_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_loss_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/tensor_protos_db_input_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_stump_func_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_sigmoid_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_arg_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_bucketize_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_boolean_mask_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_moments_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_spatial_batch_norm_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_softsign_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_clip_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_ceil_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_thresholded_relu_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_lengths_tile_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/load_save_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_roi_pool_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_sin_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_normalize_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/do_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_accuracy_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_given_tensor_byte_string_to_uint8_fill_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_scale_blobs_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_space_batch_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_replace_nan_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_softplus_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_layer_norm_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/log_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_minmax_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_acos_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_given_tensor_fill_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/negative_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_segment_reduction_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_gru_unit_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_tile_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_generate_proposals_op_util_nms_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/elementwise_sub_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_selu_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_copy_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/communicator_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_swish_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/if_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_atan_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_elementwise_linear_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_slice_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_mem_query_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/rnn/recurrent_network_executor_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/rnn/recurrent_network_blob_fetcher_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/rnn/torch_generated_recurrent_network_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_upsample_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_deform_conv_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_pow_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_tanh_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_instance_norm_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_enforce_finite_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_elementwise_div_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_summarize_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_multi_class_accuracy_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/negate_gradient_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_distance_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_gather_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/expand_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_transpose_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/reshape_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_reduction_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_relu_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/locally_connected_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_weighted_sample_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_tan_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_sequence_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_resize_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_generate_proposals_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/shape_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_abs_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_roi_align_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_channel_stats_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_pad_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/zero_gradient_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/while_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_cube_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_cross_entropy_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_piecewise_linear_transform_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_batch_gather_ops.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_dropout_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_roi_align_gradient_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/scale_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_cbrt_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/concat_split_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/free_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_prelu_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/operators/torch_generated_margin_ranking_criterion_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/queue/queue_ops_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/mpi/mpi_ops_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/core/blob_serialization_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/core/common_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/core/event_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/core/torch_generated_context_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/sgd/torch_generated_fp32_momentum_sgd_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/sgd/torch_generated_adagrad_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/sgd/torch_generated_rmsprop_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/sgd/torch_generated_yellowfin_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/sgd/learning_rate_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/sgd/torch_generated_fp16_momentum_sgd_op.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/sgd/iter_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/sgd/torch_generated_adadelta_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/sgd/torch_generated_adam_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/sgd/torch_generated_momentum_sgd_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/sgd/torch_generated_lars_op_gpu.cu.o matches
Binary file build/caffe2/CMakeFiles/torch.dir/db/create_db_op_gpu.cc.o matches
Binary file build/caffe2/CMakeFiles/reshape_op_gpu_test.dir/operators/reshape_op_gpu_test.cc.o matches
Binary file build/caffe2/CMakeFiles/net_gpu_test.dir/core/net_gpu_test.cc.o matches
build/include/c10d/ProcessGroupGloo.hpp:  // This work object is used to synchronize completion of the send or
build/include/c10d/ProcessGroupNCCL.hpp:// either WorkNCCL::wait() or WorkNCCL::synchronize(), both achieves the same
build/include/c10d/ProcessGroupNCCL.hpp:    // Same as calling synchronize() for NCCL work.
build/include/c10d/ProcessGroupNCCL.hpp:    void synchronize() override;
build/include/c10d/ProcessGroup.hpp:// process groups can be used in parallel and synchronize accordingly.
build/include/c10d/ProcessGroup.hpp:    virtual void synchronize();
test/test_multiprocessing.py:            event.synchronize()
test/test_multiprocessing.py:        event.synchronize()
test/test_multiprocessing.py:        e1.synchronize()
test/test_multiprocessing.py:        e0.synchronize()
test/test_cuda.py:        end.synchronize()
test/test_cuda.py:        s1.synchronize()
test/test_cuda.py:        # The copy() is synchronized on the current streams of both src and dst.
test/test_cuda.py:        # s2, but both copies are synchronized on s1 in the dst device. Hence,
test/test_cuda.py:        # the same device, both copy() ops are synchronized on s1.
test/test_cuda.py:        s0.synchronize()
test/test_cuda.py:        # Similarly, both copy() ops are synchronized on s0.
test/test_cuda.py:            event.synchronize()
test/test_cuda.py:    def test_cuda_synchronize(self):
test/test_cuda.py:        torch.cuda.synchronize()
test/test_cuda.py:        torch.cuda.synchronize('cuda')
test/test_cuda.py:        torch.cuda.synchronize('cuda:0')
test/test_cuda.py:        torch.cuda.synchronize(0)
test/test_cuda.py:        torch.cuda.synchronize(torch.device('cuda:0'))
test/test_cuda.py:            torch.cuda.synchronize('cuda:1')
test/test_cuda.py:            torch.cuda.synchronize(1)
test/test_cuda.py:            torch.cuda.synchronize(torch.device('cuda:1'))
test/test_cuda.py:            torch.cuda.synchronize(torch.device("cpu"))
test/test_cuda.py:            torch.cuda.synchronize("cpu")
test/test_cuda.py:        default_stream.synchronize()
test/test_cuda.py:            s1.synchronize()
test/test_cuda.py:        event.synchronize()
test/test_cuda.py:    def _stream_synchronize(self, spin_time_cycles):
test/test_cuda.py:        s.synchronize()
test/test_cuda.py:    def _event_synchronize(self, spin_time_cycles):
test/test_cuda.py:        e_tok.synchronize()
test/test_cuda.py:        s1.synchronize()
test/test_cuda.py:        for sync_func in [TestCuda._stream_synchronize,
test/test_cuda.py:                          TestCuda._event_synchronize,
test/test_cuda.py:                e_tok.synchronize()
test/test_cuda.py:        s1.synchronize()
test/test_cuda.py:            e1.synchronize()
test/test_cuda.py:        e0.synchronize()
test/test_cuda.py:        e1.synchronize()
test/test_cuda.py:            s0.synchronize()
test/test_cuda.py:        torch.cuda.current_stream().synchronize()
test/test_cuda.py:                torch.cuda.synchronize()
test/test_c10d.py:        # not necessary to run barrier here, as DDP will synchronize
test/common_utils.py:        # we don't need CUDA synchronize because the statistics are not tracked at
c10/cuda/CUDACachingAllocator.cpp:    synchronize_and_free_events(nullopt);
c10/cuda/CUDACachingAllocator.cpp:    synchronize_and_free_events(device);
c10/cuda/CUDACachingAllocator.cpp:  void synchronize_and_free_events(optional<int> device) {
c10/cuda/CUDAStream.h:* no matter which thread you use it on.  Multiple threads can synchronize
c10/cuda/CUDAStream.h:  void synchronize() const {
c10/cuda/CUDAStream.h:  // void synchronize_with(const CUDAEvent& event) const;
c10/core/impl/DeviceGuardImplInterface.h:// unsynchronized implementation probably is OK too, but I didn't want
c10/core/Stream.h: * A stream is a software mechanism used to synchronize launched kernels
c10/core/Stream.h: * kernel on the same stream is implicitly synchronized so that if I launch
c10/core/Stream.h: * time when the kernels get queued is undetermined unless you synchronize
c10/core/DeviceType.h:// This is directly synchronized with caffe2/proto/caffe2.proto, but
c10/core/DeviceType.h:// If you modify me, keep me synchronized with that file.
tags:override	torch/lib/c10d/ProcessGroupNCCL.hpp	/^    void synchronize() override;$/;"	m	class:c10d::ProcessGroupNCCL::WorkNCCL	access:public
tags:c10d::ProcessGroupNCCL::WorkNCCL::override	torch/lib/c10d/ProcessGroupNCCL.hpp	/^    void synchronize() override;$/;"	m	class:c10d::ProcessGroupNCCL::WorkNCCL	access:public
tags:synchronize	torch/lib/c10d/ProcessGroup.cpp	/^void ProcessGroup::Work::synchronize() {}$/;"	f	class:c10d::ProcessGroup::Work	signature:()
tags:c10d::ProcessGroup::Work::synchronize	torch/lib/c10d/ProcessGroup.cpp	/^void ProcessGroup::Work::synchronize() {}$/;"	f	class:c10d::ProcessGroup::Work	signature:()
tags:synchronize	torch/lib/c10d/ProcessGroupNCCL.cpp	/^void ProcessGroupNCCL::WorkNCCL::synchronize() {$/;"	f	class:c10d::ProcessGroupNCCL::WorkNCCL	signature:()
tags:c10d::ProcessGroupNCCL::WorkNCCL::synchronize	torch/lib/c10d/ProcessGroupNCCL.cpp	/^void ProcessGroupNCCL::WorkNCCL::synchronize() {$/;"	f	class:c10d::ProcessGroupNCCL::WorkNCCL	signature:()
tags:synchronize	torch/lib/c10d/ProcessGroup.hpp	/^    virtual void synchronize();$/;"	p	class:c10d::ProcessGroup::Work	access:public	signature:()
tags:c10d::ProcessGroup::Work::synchronize	torch/lib/c10d/ProcessGroup.hpp	/^    virtual void synchronize();$/;"	p	class:c10d::ProcessGroup::Work	access:public	signature:()
tags:synchronize	torch/csrc/autograd/profiler.h	/^  virtual void synchronize() {$/;"	f	struct:torch::autograd::profiler::CUDAStubs	access:public	signature:()
tags:torch::autograd::profiler::CUDAStubs::synchronize	torch/csrc/autograd/profiler.h	/^  virtual void synchronize() {$/;"	f	struct:torch::autograd::profiler::CUDAStubs	access:public	signature:()
tags:THCPStream_synchronize	torch/csrc/cuda/Stream.cpp	/^static PyObject * THCPStream_synchronize(THCPStream *self) {$/;"	f	file:	signature:(THCPStream *self)
tags:THCPEvent_synchronize	torch/csrc/cuda/Event.cpp	/^static PyObject * THCPEvent_synchronize(THCPEvent *self) {$/;"	f	file:	signature:(THCPEvent *self)
tags:override	torch/include/c10d/ProcessGroupNCCL.hpp	/^    void synchronize() override;$/;"	m	class:c10d::ProcessGroupNCCL::WorkNCCL	access:public
tags:c10d::ProcessGroupNCCL::WorkNCCL::override	torch/include/c10d/ProcessGroupNCCL.hpp	/^    void synchronize() override;$/;"	m	class:c10d::ProcessGroupNCCL::WorkNCCL	access:public
tags:synchronize	torch/include/c10d/ProcessGroup.hpp	/^    virtual void synchronize();$/;"	p	class:c10d::ProcessGroup::Work	access:public	signature:()
tags:c10d::ProcessGroup::Work::synchronize	torch/include/c10d/ProcessGroup.hpp	/^    virtual void synchronize();$/;"	p	class:c10d::ProcessGroup::Work	access:public	signature:()
tags:synchronize	torch/include/torch/csrc/autograd/profiler.h	/^  virtual void synchronize() {$/;"	f	struct:torch::autograd::profiler::CUDAStubs	access:public	signature:()
tags:torch::autograd::profiler::CUDAStubs::synchronize	torch/include/torch/csrc/autograd/profiler.h	/^  virtual void synchronize() {$/;"	f	struct:torch::autograd::profiler::CUDAStubs	access:public	signature:()
tags:mutex_	torch/include/google/protobuf/map_field.h	/^  mutable Mutex mutex_;  \/\/ The thread to synchronize map and repeated field$/;"	m	class:google::protobuf::internal::MapFieldBase	access:protected
tags:google::protobuf::internal::MapFieldBase::mutex_	torch/include/google/protobuf/map_field.h	/^  mutable Mutex mutex_;  \/\/ The thread to synchronize map and repeated field$/;"	m	class:google::protobuf::internal::MapFieldBase	access:protected
tags:synchronizeDeviceOutputs_	torch/include/gloo/cuda_broadcast_one_to_all.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaBroadcastOneToAll	access:protected
tags:gloo::CudaBroadcastOneToAll::synchronizeDeviceOutputs_	torch/include/gloo/cuda_broadcast_one_to_all.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaBroadcastOneToAll	access:protected
tags:synchronizeDeviceOutputs_	torch/include/gloo/cuda_allreduce_ring_chunked.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaAllreduceRingChunked	access:protected
tags:gloo::CudaAllreduceRingChunked::synchronizeDeviceOutputs_	torch/include/gloo/cuda_allreduce_ring_chunked.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaAllreduceRingChunked	access:protected
tags:synchronizeDeviceOutputs_	torch/include/gloo/cuda_allreduce_local.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaAllreduceLocal	access:protected
tags:gloo::CudaAllreduceLocal::synchronizeDeviceOutputs_	torch/include/gloo/cuda_allreduce_local.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaAllreduceLocal	access:protected
tags:synchronizeDeviceOutputs_	torch/include/gloo/cuda_allreduce_ring.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaAllreduceRing	access:protected
tags:gloo::CudaAllreduceRing::synchronizeDeviceOutputs_	torch/include/gloo/cuda_allreduce_ring.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaAllreduceRing	access:protected
tags:synchronize	torch/include/ATen/cuda/CUDAEvent.h	/^  void synchronize() const {$/;"	f	struct:at::cuda::CUDAEvent	access:public	signature:() const
tags:at::cuda::CUDAEvent::synchronize	torch/include/ATen/cuda/CUDAEvent.h	/^  void synchronize() const {$/;"	f	struct:at::cuda::CUDAEvent	access:public	signature:() const
tags:THFile_synchronize	torch/include/TH/THFile.h	/^TH_API void THFile_synchronize(THFile *self);$/;"	p	signature:(THFile *self)
tags:synchronize	torch/include/TH/THFilePrivate.h	/^    void (*synchronize)(THFile *self);$/;"	m	struct:THFileVTable	access:public
tags:THFileVTable::synchronize	torch/include/TH/THFilePrivate.h	/^    void (*synchronize)(THFile *self);$/;"	m	struct:THFileVTable	access:public
tags:synchronize	torch/include/c10/cuda/CUDAStream.h	/^  void synchronize() const {$/;"	f	class:c10::cuda::CUDAStream	access:public	signature:() const
tags:c10::cuda::CUDAStream::synchronize	torch/include/c10/cuda/CUDAStream.h	/^  void synchronize() const {$/;"	f	class:c10::cuda::CUDAStream	access:public	signature:() const
tags:synchronize	third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceGpu.h	/^  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void synchronize() const {$/;"	f	struct:Eigen::GpuDevice	access:public	signature:() const
tags:Eigen::GpuDevice::synchronize	third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceGpu.h	/^  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void synchronize() const {$/;"	f	struct:Eigen::GpuDevice	access:public	signature:() const
tags:synchronize	third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h	/^  EIGEN_STRONG_INLINE void synchronize() const {$/;"	f	class:Eigen::QueueInterface	access:public	signature:() const
tags:Eigen::QueueInterface::synchronize	third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h	/^  EIGEN_STRONG_INLINE void synchronize() const {$/;"	f	class:Eigen::QueueInterface	access:public	signature:() const
tags:synchronize	third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h	/^  EIGEN_STRONG_INLINE void synchronize() const {$/;"	f	struct:Eigen::SyclDevice	access:public	signature:() const
tags:Eigen::SyclDevice::synchronize	third_party/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h	/^  EIGEN_STRONG_INLINE void synchronize() const {$/;"	f	struct:Eigen::SyclDevice	access:public	signature:() const
tags:reset	third_party/protobuf/java/core/src/main/java/com/google/protobuf/RopeByteString.java	/^    public synchronized void reset() {$/;"	f	class:ByteString::InputStream	access:public	signature:()
tags:ByteString::InputStream::reset	third_party/protobuf/java/core/src/main/java/com/google/protobuf/RopeByteString.java	/^    public synchronized void reset() {$/;"	f	class:ByteString::InputStream	access:public	signature:()
tags:write	third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java	/^    public synchronized void write(int b) {$/;"	f	class:Serializable::OutputStream	access:public	signature:(int b)
tags:Serializable::OutputStream::write	third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java	/^    public synchronized void write(int b) {$/;"	f	class:Serializable::OutputStream	access:public	signature:(int b)
tags:write	third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java	/^    public synchronized void write(byte[] b, int offset, int length)  {$/;"	f	class:Serializable::OutputStream	access:public	signature:(byte[] b, int offset, int length)
tags:Serializable::OutputStream::write	third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java	/^    public synchronized void write(byte[] b, int offset, int length)  {$/;"	f	class:Serializable::OutputStream	access:public	signature:(byte[] b, int offset, int length)
tags:toByteString	third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java	/^    public synchronized ByteString toByteString() {$/;"	f	class:Serializable::OutputStream	access:public	signature:()
tags:Serializable::OutputStream::toByteString	third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java	/^    public synchronized ByteString toByteString() {$/;"	f	class:Serializable::OutputStream	access:public	signature:()
tags:size	third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java	/^    public synchronized int size() {$/;"	f	class:Serializable::OutputStream	access:public	signature:()
tags:Serializable::OutputStream::size	third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java	/^    public synchronized int size() {$/;"	f	class:Serializable::OutputStream	access:public	signature:()
tags:reset	third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java	/^    public synchronized void reset() {$/;"	f	class:Serializable::OutputStream	access:public	signature:()
tags:Serializable::OutputStream::reset	third_party/protobuf/java/core/src/main/java/com/google/protobuf/ByteString.java	/^    public synchronized void reset() {$/;"	f	class:Serializable::OutputStream	access:public	signature:()
tags:mutex_	third_party/protobuf/src/google/protobuf/map_field.h	/^  mutable Mutex mutex_;  \/\/ The thread to synchronize map and repeated field$/;"	m	class:google::protobuf::internal::MapFieldBase	access:protected
tags:google::protobuf::internal::MapFieldBase::mutex_	third_party/protobuf/src/google/protobuf/map_field.h	/^  mutable Mutex mutex_;  \/\/ The thread to synchronize map and repeated field$/;"	m	class:google::protobuf::internal::MapFieldBase	access:protected
tags:valid	third_party/gloo/docs/cuda.md	/^* Ensure the GPU buffer inputs are synchronized and valid, or$/;"	v
tags:function	third_party/gloo/docs/cuda.md	/^If no `cudaStream_t`(s) are passed to the gloo collective function, GPU buffer outputs are valid when the gloo collective function returns. Otherwise, the calling code must synchronize with the streams before using the GPU buffer outputs, i.e., explicitly with `cudaStreamSynchronize()` or inserting dependent operations in the stream.$/;"	v
tags:synchronizeDeviceOutputs_	third_party/gloo/gloo/cuda_broadcast_one_to_all.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaBroadcastOneToAll	access:protected
tags:gloo::CudaBroadcastOneToAll::synchronizeDeviceOutputs_	third_party/gloo/gloo/cuda_broadcast_one_to_all.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaBroadcastOneToAll	access:protected
tags:synchronizeDeviceOutputs_	third_party/gloo/gloo/cuda_allreduce_ring_chunked.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaAllreduceRingChunked	access:protected
tags:gloo::CudaAllreduceRingChunked::synchronizeDeviceOutputs_	third_party/gloo/gloo/cuda_allreduce_ring_chunked.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaAllreduceRingChunked	access:protected
tags:synchronizeCudaStreams	third_party/gloo/gloo/test/cuda_base_test.h	/^  void synchronizeCudaStreams() {$/;"	f	class:gloo::test::CudaFixture	access:public	signature:()
tags:gloo::test::CudaFixture::synchronizeCudaStreams	third_party/gloo/gloo/test/cuda_base_test.h	/^  void synchronizeCudaStreams() {$/;"	f	class:gloo::test::CudaFixture	access:public	signature:()
tags:synchronizeDeviceOutputs_	third_party/gloo/gloo/cuda_allreduce_local.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaAllreduceLocal	access:protected
tags:gloo::CudaAllreduceLocal::synchronizeDeviceOutputs_	third_party/gloo/gloo/cuda_allreduce_local.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaAllreduceLocal	access:protected
tags:synchronizeDeviceOutputs_	third_party/gloo/gloo/cuda_allreduce_ring.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaAllreduceRing	access:protected
tags:gloo::CudaAllreduceRing::synchronizeDeviceOutputs_	third_party/gloo/gloo/cuda_allreduce_ring.h	/^  const bool synchronizeDeviceOutputs_;$/;"	m	class:gloo::CudaAllreduceRing	access:protected
tags:debug_synchronous	third_party/cub/cub/device/dispatch/dispatch_reduce.cuh	/^    bool                debug_synchronous;              \/\/\/< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \\p false.$/;"	m	struct:cub::DispatchReduce	file:	access:public
tags:cub::DispatchReduce::debug_synchronous	third_party/cub/cub/device/dispatch/dispatch_reduce.cuh	/^    bool                debug_synchronous;              \/\/\/< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \\p false.$/;"	m	struct:cub::DispatchReduce	file:	access:public
tags:debug_synchronous	third_party/cub/cub/device/dispatch/dispatch_reduce.cuh	/^    bool                debug_synchronous;      \/\/\/< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \\p false.$/;"	m	struct:cub::DispatchSegmentedReduce	file:	access:public
tags:cub::DispatchSegmentedReduce::debug_synchronous	third_party/cub/cub/device/dispatch/dispatch_reduce.cuh	/^    bool                debug_synchronous;      \/\/\/< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \\p false.$/;"	m	struct:cub::DispatchSegmentedReduce	file:	access:public
tags:debug_synchronous	third_party/cub/cub/device/dispatch/dispatch_radix_sort.cuh	/^    bool                    debug_synchronous;      \/\/\/< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \\p false.$/;"	m	struct:cub::DispatchRadixSort	file:	access:public
tags:cub::DispatchRadixSort::debug_synchronous	third_party/cub/cub/device/dispatch/dispatch_radix_sort.cuh	/^    bool                    debug_synchronous;      \/\/\/< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \\p false.$/;"	m	struct:cub::DispatchRadixSort	file:	access:public
tags:debug_synchronous	third_party/cub/cub/device/dispatch/dispatch_radix_sort.cuh	/^    bool                    debug_synchronous;      \/\/\/< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \\p false.$/;"	m	struct:cub::DispatchSegmentedRadixSort	file:	access:public
tags:cub::DispatchSegmentedRadixSort::debug_synchronous	third_party/cub/cub/device/dispatch/dispatch_radix_sort.cuh	/^    bool                    debug_synchronous;      \/\/\/< [in] Whether or not to synchronize the stream after every kernel launch to check for errors.  Also causes launch configurations to be printed to the console.  Default is \\p false.$/;"	m	struct:cub::DispatchSegmentedRadixSort	file:	access:public
tags:synchronize	aten/src/ATen/cuda/CUDAEvent.h	/^  void synchronize() const {$/;"	f	struct:at::cuda::CUDAEvent	access:public	signature:() const
tags:at::cuda::CUDAEvent::synchronize	aten/src/ATen/cuda/CUDAEvent.h	/^  void synchronize() const {$/;"	f	struct:at::cuda::CUDAEvent	access:public	signature:() const
tags:synchronize	aten/src/ATen/hip/impl/HIPStreamMasqueradingAsCUDA.h	/^  void synchronize() const   { stream_.synchronize(); }$/;"	f	class:c10::hip::HIPStreamMasqueradingAsCUDA	access:public	signature:() const
tags:c10::hip::HIPStreamMasqueradingAsCUDA::synchronize	aten/src/ATen/hip/impl/HIPStreamMasqueradingAsCUDA.h	/^  void synchronize() const   { stream_.synchronize(); }$/;"	f	class:c10::hip::HIPStreamMasqueradingAsCUDA	access:public	signature:() const
tags:THFile_synchronize	aten/src/TH/THFile.h	/^TH_API void THFile_synchronize(THFile *self);$/;"	p	signature:(THFile *self)
tags:synchronize	aten/src/TH/THFilePrivate.h	/^    void (*synchronize)(THFile *self);$/;"	m	struct:THFileVTable	access:public
tags:THFileVTable::synchronize	aten/src/TH/THFilePrivate.h	/^    void (*synchronize)(THFile *self);$/;"	m	struct:THFileVTable	access:public
tags:THFile_synchronize	aten/src/TH/THFile.cpp	/^void THFile_synchronize(THFile *self)$/;"	f	signature:(THFile *self)
tags:THDiskFile_synchronize	aten/src/TH/THDiskFile.cpp	/^static void THDiskFile_synchronize(THFile *self)$/;"	f	file:	signature:(THFile *self)
tags:THMemoryFile_synchronize	aten/src/TH/THMemoryFile.cpp	/^static void THMemoryFile_synchronize(THFile *self)$/;"	f	file:	signature:(THFile *self)
tags:synchronize	build/lib.linux-x86_64-3.7/torch/include/torch/csrc/autograd/profiler.h	/^  virtual void synchronize() {$/;"	f	struct:torch::autograd::profiler::CUDAStubs	access:public	signature:()
tags:torch::autograd::profiler::CUDAStubs::synchronize	build/lib.linux-x86_64-3.7/torch/include/torch/csrc/autograd/profiler.h	/^  virtual void synchronize() {$/;"	f	struct:torch::autograd::profiler::CUDAStubs	access:public	signature:()
tags:synchronize	build/lib.linux-x86_64-3.7/torch/include/ATen/cuda/CUDAEvent.h	/^  void synchronize() const {$/;"	f	struct:at::cuda::CUDAEvent	access:public	signature:() const
tags:at::cuda::CUDAEvent::synchronize	build/lib.linux-x86_64-3.7/torch/include/ATen/cuda/CUDAEvent.h	/^  void synchronize() const {$/;"	f	struct:at::cuda::CUDAEvent	access:public	signature:() const
tags:THFile_synchronize	build/lib.linux-x86_64-3.7/torch/include/TH/THFile.h	/^TH_API void THFile_synchronize(THFile *self);$/;"	p	signature:(THFile *self)
tags:synchronize	build/lib.linux-x86_64-3.7/torch/include/TH/THFilePrivate.h	/^    void (*synchronize)(THFile *self);$/;"	m	struct:THFileVTable	access:public
tags:THFileVTable::synchronize	build/lib.linux-x86_64-3.7/torch/include/TH/THFilePrivate.h	/^    void (*synchronize)(THFile *self);$/;"	m	struct:THFileVTable	access:public
tags:synchronize	build/lib.linux-x86_64-3.7/torch/include/c10/cuda/CUDAStream.h	/^  void synchronize() const {$/;"	f	class:c10::cuda::CUDAStream	access:public	signature:() const
tags:c10::cuda::CUDAStream::synchronize	build/lib.linux-x86_64-3.7/torch/include/c10/cuda/CUDAStream.h	/^  void synchronize() const {$/;"	f	class:c10::cuda::CUDAStream	access:public	signature:() const
caffe2/mobile/contrib/libopencl-stub/include/CL/cl.hpp:    inline void fence() { __sync_synchronize(); }
caffe2/mobile/contrib/ios/mpscnn/mpscnn.mm:     * temporary image. We don't want to synchronize the parent wrapper because
caffe2/mobile/contrib/ios/mpscnn/mpscnn.mm:     * command buffer,we need to synchronize(commit) it since it won't be used
caffe2/mobile/contrib/ios/mpscnn/mpscnn.mm:      parent->synchronize();
caffe2/mobile/contrib/ios/mpscnn/mpscnn.mm:  void synchronize() {
caffe2/mobile/contrib/ios/mpscnn/mpscnn.mm:    synchronize();
caffe2/contrib/gloo/gloo_test.py:    def synchronize(self, store_handler, value, comm_rank=None):
caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
caffe2/contrib/gloo/gloo_test.py:        blob_size = self.synchronize(
caffe2/contrib/gloo/gloo_test.py:        num_blobs = self.synchronize(
caffe2/contrib/opencl/OpenCL/cl.hpp:        __sync_synchronize();
caffe2/contrib/shm_mutex/shm_mutex.h: * to synchronize CUDA calls (memory allocation and frees) and
caffe2/contrib/nccl/cuda_nccl_gpu.cc:  // children streams, so the children streams are synchronized WRT
caffe2/python/data_parallel_model.py:                        to synchronize shards before a training epoch starts.
caffe2/python/data_parallel_model.py:    # synchronized values by the training net
caffe2/operators/utility_ops.cu:  // Note: we must synchronize here so we can inspect the result
caffe2/operators/prefetch_op.h:// the waiting producer after we synchronize). This is a special-case
caffe2/core/context_gpu.cu:  // destructor of context synchronizes
caffe2/core/context_gpu.h:    //   it's preferrable to synchronize in the destructor
caffe2/core/event.h:// Prepares context to synchronize device part of operation.
caffe2/observers/profile_observer.h: * NOTE: Currently this observer only supports synchronized computation
